<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>书生·浦语 on 平方君的后花园</title><link>https://i-square.github.io/tags/%E4%B9%A6%E7%94%9F%E6%B5%A6%E8%AF%AD/</link><description>Recent content in 书生·浦语 on 平方君的后花园</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 11 Jan 2024 16:56:30 +0800</lastBuildDate><atom:link href="https://i-square.github.io/tags/%E4%B9%A6%E7%94%9F%E6%B5%A6%E8%AF%AD/index.xml" rel="self" type="application/rss+xml"/><item><title>书生·浦语大模型实战营（三）：基于 InternLM 和 LangChain 搭建你的知识库</title><link>https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/</link><pubDate>Thu, 11 Jan 2024 16:56:30 +0800</pubDate><guid>https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/</guid><description>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/head.webp" alt="Featured image of post 书生·浦语大模型实战营（三）：基于 InternLM 和 LangChain 搭建你的知识库" />&lt;h2 id="前言">前言&lt;/h2>
&lt;p>本文为&lt;a class="link" href="https://github.com/InternLM/tutorial" target="_blank" rel="noopener"
>书生·浦语大模型实战营&lt;/a>的课程笔记系列第三节&lt;/p>
&lt;ul>
&lt;li>教学视频：&lt;a class="link" href="https://www.bilibili.com/video/BV1sT4y1p71V/" target="_blank" rel="noopener"
>B站 BV1sT4y1p71V&lt;/a>&lt;/li>
&lt;li>配套文档：&lt;a class="link" href="https://github.com/InternLM/tutorial/blob/main/langchain/readme.md" target="_blank" rel="noopener"
>InternLM/tutorial langchain&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="llm的局限性">LLM的局限性&lt;/h2>
&lt;ul>
&lt;li>知识时效性受限：如何让LLM能够获取最新的知识&lt;/li>
&lt;li>专业能力有限：如何打造垂域大模型&lt;/li>
&lt;li>定制化成本高：如何打造个人专属的LLM应用&lt;/li>
&lt;/ul>
&lt;h3 id="大模型开发范式">大模型开发范式&lt;/h3>
&lt;p>解决局限性问题的两种方式是：&lt;/p>
&lt;h4 id="1-rag">1. RAG&lt;/h4>
&lt;p>RAG: Retrieval Augmented Generation，使用外挂数据库，检索相关知识增强生成结果，特点：&lt;/p>
&lt;ul>
&lt;li>低成本&lt;/li>
&lt;li>可实时更新&lt;/li>
&lt;li>受基座模型影响大&lt;/li>
&lt;li>单次回答知识有限&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/RAG_flow.webp"
width="690"
height="668"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/RAG_flow_hue435df51197f5a26305e3a4eed1f11d8_13242_480x0_resize_q75_h2_box_2.webp 480w, https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/RAG_flow_hue435df51197f5a26305e3a4eed1f11d8_13242_1024x0_resize_q75_h2_box_2.webp 1024w"
loading="lazy"
alt="RAG_frame"
class="gallery-image"
data-flex-grow="103"
data-flex-basis="247px"
>&lt;/p>
&lt;ul>
&lt;li>流程
&lt;ol>
&lt;li>输入文本转化为向量&lt;/li>
&lt;li>在向量数据库中匹配相似文本&lt;/li>
&lt;li>作为prompt在大模型中寻找答案&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h4 id="2-finetune">2. Finetune&lt;/h4>
&lt;p>也即通称的微调，特点：&lt;/p>
&lt;ul>
&lt;li>可个性化微调&lt;/li>
&lt;li>知识覆盖面广&lt;/li>
&lt;li>成本高昂&lt;/li>
&lt;li>无法实时更新&lt;/li>
&lt;/ul>
&lt;h2 id="基于-langchain-搭建-rag-应用">基于 LangChain 搭建 RAG 应用&lt;/h2>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/rag_based_langchain.webp"
width="1104"
height="790"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/rag_based_langchain_hudd7e07a76c7f5daf5a1b69019809a62c_30560_480x0_resize_q75_h2_box_2.webp 480w, https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/rag_based_langchain_hudd7e07a76c7f5daf5a1b69019809a62c_30560_1024x0_resize_q75_h2_box_2.webp 1024w"
loading="lazy"
alt="rag_based_langchain"
class="gallery-image"
data-flex-grow="139"
data-flex-basis="335px"
>&lt;/p>
&lt;h3 id="langchain框架简介">LangChain框架简介&lt;/h3>
&lt;p>LangChain 框架是一个开源工具，通过为各种 LLM 提供通用接口来简化应用程序的开发流程，帮助开发者自由构建 LLM 应用。&lt;/p>
&lt;p>LangChain 的核心组成模块：&lt;/p>
&lt;ul>
&lt;li>链 (Chains) ：将组件组合实现端到端应用，通过一个对象封装实现一系列LLM操作&lt;/li>
&lt;li>Eg. 检索问答链，覆盖实现了 RAG （检索增强生成）的全部流程&lt;/li>
&lt;/ul>
&lt;h3 id="构建向量数据库">构建向量数据库&lt;/h3>
&lt;h4 id="加载源文件">加载源文件&lt;/h4>
&lt;ul>
&lt;li>确定源文件类型，针对不同类型的源文件选用不同的加载器
&lt;ul>
&lt;li>核心在于将带格式的文本转化为无格式的字符串&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="文档分块">文档分块&lt;/h4>
&lt;ul>
&lt;li>由于单个文档往往超过模型上下文上限，我们需要对加载的文档进行切分
&lt;ul>
&lt;li>一般按字符串长度进行分割&lt;/li>
&lt;li>可以手动控制分割块的长度和重叠区间长度&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h4 id="文档向量化">文档向量化&lt;/h4>
&lt;ul>
&lt;li>使用向量数据库来支持语义检索，需要将文档向量化存入向量数据库
&lt;ul>
&lt;li>可以使用任意一种 Embedding 模型来进行向量化&lt;/li>
&lt;li>可以使用多种支持语义检索的向量数据库，一般使用轻量级的 Chroma&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="搭建知识库助手">搭建知识库助手&lt;/h3>
&lt;h4 id="将-internlm-接入-langchain">将 InternLM 接入 LangChain&lt;/h4>
&lt;ul>
&lt;li>LangChain 支持自定义 LLM，可以直接接入到框架中&lt;/li>
&lt;li>我们只需将 lnternLM 部署在本地，并封装一个自定义 LLM 类，调用本地 lnternLM 即可&lt;/li>
&lt;/ul>
&lt;h4 id="构建检索问答链">构建检索问答链&lt;/h4>
&lt;ul>
&lt;li>LangChain 提供了检索问答链模版，可以自动实现知识检索、Prompt 嵌入、LLM 问答的全部流程&lt;/li>
&lt;li>将基于 lnternLM 的自定义 LLM 和已构建的向量数据库接入到检索问答链的上游&lt;/li>
&lt;li>调用检索问答链，即可实现知识库助手的核心功能&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/query_answer_chain.webp"
width="808"
height="425"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/query_answer_chain_hu7a3dcadb9394bffe8a8eafd5905ccdc3_7082_480x0_resize_q75_h2_box_2.webp 480w, https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/screenshots/query_answer_chain_hu7a3dcadb9394bffe8a8eafd5905ccdc3_7082_1024x0_resize_q75_h2_box_2.webp 1024w"
loading="lazy"
alt="query_answer_chain"
class="gallery-image"
data-flex-grow="190"
data-flex-basis="456px"
>&lt;/p>
&lt;h4 id="rag-方案优化建议">RAG 方案优化建议&lt;/h4>
&lt;ul>
&lt;li>基于RAG的问答系统性能核心受限于：
&lt;ul>
&lt;li>检索精度&lt;/li>
&lt;li>Prompt性能&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>一些可能的优化点：
&lt;ul>
&lt;li>检索方面：
&lt;ul>
&lt;li>基于语义分割，保证每一个chunk的语义完整&lt;/li>
&lt;li>给每一个chunk生成概括式索引，检索时匹配索引&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Prompt方面
&lt;ul>
&lt;li>迭代优化Prompt策略&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="作业">作业&lt;/h2>
&lt;h3 id="基础作业">基础作业&lt;/h3>
&lt;blockquote>
&lt;p>目标：复现课程知识库助手搭建过程 (截图)&lt;/p>
&lt;/blockquote>
&lt;h4 id="环境配置">环境配置&lt;/h4>
&lt;p>本次沿用上节课程配置的 &lt;a class="link" href="https://studio.intern-ai.org.cn/" target="_blank" rel="noopener"
>InternStudio&lt;/a> 平台开发机，省去了一些环境准备的时间，过程不再赘述，教学文档中有详细步骤。&lt;/p>
&lt;h4 id="构建向量数据库-1">构建向量数据库&lt;/h4>
&lt;ul>
&lt;li>终端命令：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/create_db_cmd.png"
width="2173"
height="278"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/create_db_cmd_hud8229e4d622c983353773f9945aaccd3_24332_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/create_db_cmd_hud8229e4d622c983353773f9945aaccd3_24332_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="create_db_cmd"
class="gallery-image"
data-flex-grow="781"
data-flex-basis="1875px"
>&lt;/p>
&lt;h4 id="web-demo">Web Demo&lt;/h4>
&lt;ul>
&lt;li>终端命令：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/gradio_demo_cmd.png"
width="2180"
height="258"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/gradio_demo_cmd_hua4068ac19bb600449ace1e52d26a44e6_22079_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/gradio_demo_cmd_hua4068ac19bb600449ace1e52d26a44e6_22079_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="gradio_demo_cmd"
class="gallery-image"
data-flex-grow="844"
data-flex-basis="2027px"
>&lt;/p>
&lt;ul>
&lt;li>结果图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/gradio_demo.png"
width="1543"
height="874"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/gradio_demo_hu1cb02b189be1795ff0b6408c8207f27a_31308_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/homework/gradio_demo_hu1cb02b189be1795ff0b6408c8207f27a_31308_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="gradio_demo"
class="gallery-image"
data-flex-grow="176"
data-flex-basis="423px"
>&lt;/p>
&lt;ul>
&lt;li>分析：从结果来看，大模型回答出了有关23年12月的问题，这不在它本身训练数据中，证明检索问答链是有效的。&lt;/li>
&lt;/ul>
&lt;h3 id="进阶作业">进阶作业&lt;/h3>
&lt;blockquote>
&lt;p>目标：选择一个垂直领域，收集该领域的专业资料构建专业知识库，并搭建专业问答助手，并在 &lt;a class="link" href="https://openxlab.org.cn/apps" target="_blank" rel="noopener"
>OpenXLab&lt;/a> 上成功部署（截图，并提供应用地址）&lt;/p>
&lt;/blockquote>
&lt;p>由于时间关系，进阶作业没有计划做&lt;/p></description></item><item><title>书生·浦语大模型实战营（二）：轻松玩转书生·浦语大模型趣味Demo</title><link>https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/</link><pubDate>Wed, 10 Jan 2024 15:44:22 +0800</pubDate><guid>https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/</guid><description>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/head.webp" alt="Featured image of post 书生·浦语大模型实战营（二）：轻松玩转书生·浦语大模型趣味Demo" />&lt;h2 id="前言">前言&lt;/h2>
&lt;p>本文为&lt;a class="link" href="https://github.com/InternLM/tutorial" target="_blank" rel="noopener"
>书生·浦语大模型实战营&lt;/a>的课程笔记系列第二节&lt;/p>
&lt;ul>
&lt;li>教学视频：&lt;a class="link" href="https://www.bilibili.com/video/BV1Ci4y1z72H/" target="_blank" rel="noopener"
>B站 BV1Ci4y1z72H&lt;/a>&lt;/li>
&lt;li>配套文档：&lt;a class="link" href="https://github.com/InternLM/tutorial/blob/main/helloworld/hello_world.md" target="_blank" rel="noopener"
>InternLM/tutorial helloworld&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="笔记">笔记&lt;/h2>
&lt;p>由于配套的说明文档已经记录的相当详细并且图文并茂，这节课丝毫没有记录笔记的必要，所以本文仅仅记录课后作业&lt;/p>
&lt;h2 id="基础作业">基础作业&lt;/h2>
&lt;h3 id="hf模型下载">HF模型下载&lt;/h3>
&lt;blockquote>
&lt;p>目标：熟悉 &lt;code>hugging face&lt;/code> 下载功能，使用 &lt;code>huggingface_hub&lt;/code> python 包，下载 &lt;code>InternLM-20B&lt;/code> 的 &lt;code>config.json&lt;/code> 文件到本地（需截图下载过程）。&lt;/p>
&lt;/blockquote>
&lt;p>这个无需多言，只是基本的命令使用，需要注意的是，由于众所周知的原因，国内直接下载 &lt;code>hugging face&lt;/code> 是不行的，这里使用镜像站 &lt;a class="link" href="https://hf-mirror.com/" target="_blank" rel="noopener"
>hf-mirror&lt;/a>。&lt;/p>
&lt;ul>
&lt;li>结果图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/0_hf_download.png"
width="1621"
height="776"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/0_hf_download_hu499ec520d3afab854757ac9da67bb810_11368_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/0_hf_download_hu499ec520d3afab854757ac9da67bb810_11368_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="0_hf_download"
class="gallery-image"
data-flex-grow="208"
data-flex-basis="501px"
>&lt;/p>
&lt;h3 id="浦语7b模型部署demo">浦语7B模型部署demo&lt;/h3>
&lt;blockquote>
&lt;p>目标：使用 InternLM-Chat-7B 模型生成 300 字的小故事（需截图）。&lt;/p>
&lt;/blockquote>
&lt;p>这里我们可以使用两种demo来完成，分别是 &lt;code>cli_demo&lt;/code> 和 &lt;code>web_demo&lt;/code>，详细步骤参考配套教学文档，以下为大致总结：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>环境准备：&lt;/strong>
&lt;ul>
&lt;li>在 &lt;a class="link" href="https://studio.intern-ai.org.cn/" target="_blank" rel="noopener"
>InternStudio&lt;/a> 平台选择 A100(1/4) 的配置，使用 &lt;code>Cuda11.7-conda&lt;/code> 镜像。&lt;/li>
&lt;li>打开开发机，进入终端，切换到 &lt;code>bash&lt;/code> 环境。&lt;/li>
&lt;li>使用提供的脚本克隆并激活 &lt;code>pytorch 2.0.1&lt;/code> 的 &lt;code>conda&lt;/code> 环境，然后安装所需依赖。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>模型下载：&lt;/strong>
&lt;ul>
&lt;li>复制已准备好的 &lt;code>InternLM&lt;/code> 模型到指定目录，或使用 &lt;code>modelscope&lt;/code> 中的 &lt;code>snapshot_download&lt;/code> 函数下载模型（&lt;strong>推荐&lt;/strong>，跑满带宽），或在 &lt;code>huggingface&lt;/code>、&lt;code>OpenXLab&lt;/code> 等处下载。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>代码准备：&lt;/strong>
&lt;ul>
&lt;li>在 &lt;code>/root&lt;/code> 路径下新建 &lt;code>code&lt;/code> 目录，&lt;code>clone&lt;/code> 指定版本的代码。&lt;/li>
&lt;li>在 &lt;code>/root/code/InternLM&lt;/code> 目录下新建 &lt;code>cli_demo.py&lt;/code> 文件，使用 &lt;code>transformers&lt;/code> 和 &lt;code>torch&lt;/code> 库运行大模型。&lt;/li>
&lt;li>修改 &lt;code>/root/code/InternLM/web_demo.py&lt;/code> 中的模型路径为本地路径。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>终端运行：&lt;/strong>
&lt;ul>
&lt;li>运行 &lt;code>xxx_demo.py&lt;/code> 文件，即可体验 &lt;code>InternLM-Chat-7B&lt;/code> 模型的对话能力。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;p>&lt;em>使用的prompt：帮我生成一个300字的小故事，主角是打工人叫平方君，内容是他通过不断努力升职加薪、当上总经理、出任CEO、迎娶白富美、走上人生巅峰的励志故事&lt;/em>&lt;/p>
&lt;h4 id="cli_demo">cli_demo&lt;/h4>
&lt;ul>
&lt;li>结果图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_cli_demo.png"
width="1577"
height="274"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_cli_demo_hu99fda8c5f448e7626395faf60b70fb9d_12647_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_cli_demo_hu99fda8c5f448e7626395faf60b70fb9d_12647_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="1_cli_demo"
class="gallery-image"
data-flex-grow="575"
data-flex-basis="1381px"
>&lt;/p>
&lt;h4 id="web_demo">web_demo&lt;/h4>
&lt;p>由于 &lt;a class="link" href="https://studio.intern-ai.org.cn/" target="_blank" rel="noopener"
>InternStudio&lt;/a> 平台的开发机不能直接通过web访问，所以需要做一下端口映射，原理是利用 &lt;code>ssh&lt;/code> 做端口转发。&lt;/p>
&lt;p>在本地主机运行：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">ssh -CNg -L 8008:127.0.0.1:8008 root@ssh.intern-ai.org.cn -p &lt;span class="m">34664&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>各部分解释如下：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>ssh:&lt;/strong> 启动SSH客户端程序。&lt;/li>
&lt;li>&lt;strong>-C:&lt;/strong> 启用压缩。数据传输时进行压缩，提高传输效率。&lt;/li>
&lt;li>&lt;strong>-N:&lt;/strong> 不执行任何命令，主要用于纯粹建立连接。在这里，它告诉SSH客户端不要执行远程命令。&lt;/li>
&lt;li>&lt;strong>-g:&lt;/strong> 允许远程主机连接到本地的转发端口。在这里，它允许其他主机连接到本地端口8008。&lt;/li>
&lt;li>&lt;strong>-L 8008:127.0.0.1:8008:&lt;/strong> 设置本地端口转发。将本地端口8008转发到远程主机的127.0.0.1（即本地主机）的8008端口。&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="mailto:root@ssh.intern-ai.org.cn" >root@ssh.intern-ai.org.cn&lt;/a>:&lt;/strong> 远程SSH服务器的用户名和主机地址。&lt;/li>
&lt;li>&lt;strong>-p 34664:&lt;/strong> 指定SSH服务器的端口号。&lt;/li>
&lt;/ul>
&lt;p>此命令的目的是在本地端口&lt;code>8008&lt;/code>上创建一个SSH隧道，将流量转发到远程服务器上的相同端口，同时允许其他主机通过该远程服务器连接到本地端口。&lt;/p>
&lt;hr>
&lt;p>作业部分：&lt;/p>
&lt;ul>
&lt;li>终端命令：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_web_demo_cmd.png"
width="1199"
height="315"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_web_demo_cmd_hu21a629fe185c1cf89f832c6c759b0d48_11983_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_web_demo_cmd_hu21a629fe185c1cf89f832c6c759b0d48_11983_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="1_web_demo_cmd"
class="gallery-image"
data-flex-grow="380"
data-flex-basis="913px"
>&lt;/p>
&lt;ul>
&lt;li>结果图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_web_demo.png"
width="744"
height="783"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_web_demo_hu710490253f319d20449554139d9d539f_37125_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/1_web_demo_hu710490253f319d20449554139d9d539f_37125_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="1_web_demo"
class="gallery-image"
data-flex-grow="95"
data-flex-basis="228px"
>&lt;/p>
&lt;h2 id="进阶作业可选做">进阶作业（可选做）&lt;/h2>
&lt;h3 id="lagent部署demo">Lagent部署demo&lt;/h3>
&lt;blockquote>
&lt;p>目标：完成 &lt;code>Lagent&lt;/code> 工具调用 Demo 创作部署（需截图）&lt;/p>
&lt;/blockquote>
&lt;p>由于涉及到图形化操作，这里只有 &lt;code>web_demo&lt;/code>，详细步骤参考配套教学文档，以下为大致总结：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>环境准备：&lt;/strong>
&lt;ul>
&lt;li>沿用之前的环境。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>模型下载：&lt;/strong>
&lt;ul>
&lt;li>不再赘述。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Lagent 安装和修改代码：&lt;/strong>
&lt;ul>
&lt;li>切换到 &lt;code>/root/code&lt;/code> 目录，克隆 &lt;code>lagent&lt;/code> 仓库，并通过 &lt;code>pip install -e .&lt;/code> 源码安装。&lt;/li>
&lt;li>修改 &lt;code>react_web_demo.py&lt;/code> 文件，替换为相应代码。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Demo 运行：&lt;/strong>
&lt;ul>
&lt;li>在终端运行 &lt;code>streamlit&lt;/code> 命令，启动 &lt;code>Web&lt;/code> 页面。&lt;/li>
&lt;li>在浏览器中访问 &lt;code>http://127.0.0.1:8008&lt;/code> 查看 Demo。&lt;/li>
&lt;li>选择 &lt;code>InternLM&lt;/code> 模型，输入问题，观察 &lt;code>Lagent&lt;/code> 调度并处理的过程。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>作业部分：&lt;/p>
&lt;ul>
&lt;li>终端命令：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/3_lagent_web_demo_cmd.png"
width="1215"
height="372"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/3_lagent_web_demo_cmd_huf9307425b8e4bd7b19b23abd694151b4_22417_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/3_lagent_web_demo_cmd_huf9307425b8e4bd7b19b23abd694151b4_22417_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="3_lagent_web_demo_cmd"
class="gallery-image"
data-flex-grow="326"
data-flex-basis="783px"
>&lt;/p>
&lt;ul>
&lt;li>结果图：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/3_lagent_web_demo.png"
width="1152"
height="990"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/3_lagent_web_demo_hu8077bf684fa137e1dd412753bccca3a1_25738_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/3_lagent_web_demo_hu8077bf684fa137e1dd412753bccca3a1_25738_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="3_lagent_web_demo"
class="gallery-image"
data-flex-grow="116"
data-flex-basis="279px"
>&lt;/p>
&lt;h3 id="浦语灵笔部署demo">浦语·灵笔部署demo&lt;/h3>
&lt;blockquote>
&lt;p>目标：完成浦语·灵笔的图文理解及创作部署（需截图）&lt;/p>
&lt;/blockquote>
&lt;p>由于涉及到图形化操作，这里也只有 &lt;code>web_demo&lt;/code>，详细步骤参考配套教学文档，以下为大致总结：&lt;/p>
&lt;ol>
&lt;li>&lt;strong>环境准备：&lt;/strong>
&lt;ul>
&lt;li>继续沿用之前的环境。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>模型下载：&lt;/strong>
&lt;ul>
&lt;li>用同样的方式，准备 &lt;code>internlm-xcomposer-7b&lt;/code> 模型到指定目录。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>代码准备：&lt;/strong>
&lt;ul>
&lt;li>在 &lt;code>/root/code&lt;/code> 目录下克隆 &lt;code>InternLM-XComposer&lt;/code> 仓库的代码，切换到指定的 commit 版本，以便对齐教学结果。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>Demo 运行：&lt;/strong>
&lt;ul>
&lt;li>在终端运行 &lt;code>web_demo.py&lt;/code> 文件，启动 &lt;code>Web&lt;/code> 页面。&lt;/li>
&lt;li>在浏览器中访问 &lt;code>http://127.0.0.1:8008&lt;/code>，体验图文理解创作的功能。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>作业部分： 从终端的log来看，浦语·灵笔的创作流程大致上是先用语言模型生成文章，再选取合适的图片插入点，然后在数据库里根据关键词搜索匹配的图片，之后下载图片，并组合生成一份 &lt;code>markdown&lt;/code> 文档。&lt;/p>
&lt;ul>
&lt;li>终端命令：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo_cmd.png"
width="2206"
height="5648"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo_cmd_huc420ff8248919de7c2b5d7333db1365b_566511_480x0_resize_box_3.png 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo_cmd_huc420ff8248919de7c2b5d7333db1365b_566511_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="4_xcomposer_web_demo_cmd"
class="gallery-image"
data-flex-grow="39"
data-flex-basis="93px"
>&lt;/p>
&lt;ul>
&lt;li>结果图1-图文生成：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo1.webp"
width="1649"
height="1314"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo1_hu40027a68ac8fe4cd5dcffe9b97848ec3_90100_480x0_resize_q75_h2_box_2.webp 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo1_hu40027a68ac8fe4cd5dcffe9b97848ec3_90100_1024x0_resize_q75_h2_box_2.webp 1024w"
loading="lazy"
alt="4_xcomposer_web_demo1"
class="gallery-image"
data-flex-grow="125"
data-flex-basis="301px"
>&lt;/p>
&lt;ul>
&lt;li>结果图2-多模态对话：&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo2.webp"
width="1581"
height="1105"
srcset="https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo2_hu22c55a1ac784658fb8301f51d84583ab_54784_480x0_resize_q75_h2_box_2.webp 480w, https://i-square.github.io/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/homework/4_xcomposer_web_demo2_hu22c55a1ac784658fb8301f51d84583ab_54784_1024x0_resize_q75_h2_box_2.webp 1024w"
loading="lazy"
alt="4_xcomposer_web_demo2"
class="gallery-image"
data-flex-grow="143"
data-flex-basis="343px"
>&lt;/p></description></item><item><title>书生·浦语大模型实战营（一）：书生·浦语大模型全链路开源体系</title><link>https://i-square.github.io/p/InternLM-tutorial-campsection1-LLM-Full-Stack-Open-Source-Ecosystem/</link><pubDate>Tue, 09 Jan 2024 18:50:55 +0800</pubDate><guid>https://i-square.github.io/p/InternLM-tutorial-campsection1-LLM-Full-Stack-Open-Source-Ecosystem/</guid><description>&lt;img src="https://i-square.github.io/p/InternLM-tutorial-campsection1-LLM-Full-Stack-Open-Source-Ecosystem/camp.webp" alt="Featured image of post 书生·浦语大模型实战营（一）：书生·浦语大模型全链路开源体系" />&lt;h2 id="前言">前言&lt;/h2>
&lt;p>本文为&lt;a class="link" href="https://github.com/InternLM/tutorial" target="_blank" rel="noopener"
>书生·浦语大模型实战营&lt;/a>的课程笔记系列第一节，课程地址：&lt;a class="link" href="https://www.bilibili.com/video/BV1Rc411b7ns/" target="_blank" rel="noopener"
>https://www.bilibili.com/video/BV1Rc411b7ns/&lt;/a>&lt;/p>
&lt;h2 id="从专用模型到通用大模型">从专用模型到通用大模型&lt;/h2>
&lt;p>在过去，人工智能领域的发展一直遵循着一个基本原则：一个模型对应一个场景或者任务。然而，随着技术的进步和需求的增长，这一格局正在发生深刻的变化。如今，我们正迈向一个新的时代，一个模型不再局限于一个场景或任务，而是可以应用于多个场景、多模态的复杂环境中。&lt;/p>
&lt;h2 id="书生浦语大模型发展历程">书生·浦语大模型发展历程&lt;/h2>
&lt;p>书生·浦语大模型的发展历程彰显了这一变革的重要性。它从轻量级的7B社区模型，逐步升级到中量级的20B商业模型，再到重量级的123B全场景模型。这一演进不仅仅是在模型规模上的提升，更是对多模态、多场景应用需求的积极响应。&lt;/p>
&lt;h3 id="interlm-20b全面领先的开源模型">InterLM-20B：全面领先的开源模型&lt;/h3>
&lt;p>&lt;a class="link" href="https://github.com/InternLM/InternLM" target="_blank" rel="noopener"
>InterLM-20B&lt;/a>是一款千亿参数级别的开源模型，其性能在全球范围内处于领先地位。与相近规模的Llama-33B、Llama2-13B以及国内主流的7B、13B开源模型相比，InterLM-20B在不足三分之一的参数量下，却达到了Llama2-70B的水平。&lt;/p>
&lt;h2 id="从模型到应用六个关键步骤">从模型到应用：六个关键步骤&lt;/h2>
&lt;h3 id="第一步模型选型">第一步：模型选型&lt;/h3>
&lt;p>在应用场景中，根据多个大模型的相关维度进行能力比较，并进行模型评测。初步选型后，可确定意向大模型。&lt;/p>
&lt;h3 id="第二步评估业务场景复杂度">第二步：评估业务场景复杂度&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>业务场景简单：&lt;/strong> 如果业务场景不太复杂，可以直接将选定的模型应用于场景中。&lt;/li>
&lt;li>&lt;strong>业务场景复杂：&lt;/strong> 对于复杂场景，通常直接使用开源模型难以满足需求，需要进一步微调、进行prompt工程等构建工作。&lt;/li>
&lt;/ul>
&lt;h3 id="第三步判断微调策略">第三步：判断微调策略&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>全参数微调：&lt;/strong> 若算力足够，可以进行全参数微调，提高模型性能。&lt;/li>
&lt;li>&lt;strong>部分参数微调：&lt;/strong> 如果算力受限，只能进行部分参数微调，固定大部分参数，调整一小部分参数。&lt;/li>
&lt;/ul>
&lt;h3 id="第四步构建智能体">第四步：构建智能体&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>模型与环境交互：&lt;/strong> 考虑模型与环境的交互，特别是如果需要调用外部API或与已有业务数据库交互，则需要构建智能体。&lt;/li>
&lt;li>&lt;strong>无环境交互：&lt;/strong> 如果模型在业务场景中不需要与环境进行交互，可以直接将微调好的模型应用于场景。&lt;/li>
&lt;/ul>
&lt;h3 id="第五步模型评测与应用上线">第五步：模型评测与应用上线&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>模型评测：&lt;/strong> 进行模型评测，确保在实际场景中表现良好。&lt;/li>
&lt;li>&lt;strong>上线或迭代：&lt;/strong> 根据评测结果，决定是否上线应用或者继续迭代模型。&lt;/li>
&lt;/ul>
&lt;h3 id="第六步模型部署">第六步：模型部署&lt;/h3>
&lt;p>考虑软件系统相关性能、安全、功能等方面内容：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>资源优化：&lt;/strong> 考虑如何以更少的资源部署模型。&lt;/li>
&lt;li>&lt;strong>吞吐量提升：&lt;/strong> 提升整个应用的吞吐量，确保在生产环境中的性能表现。&lt;/li>
&lt;/ul>
&lt;p>这六个步骤构成了从选择模型到应用部署的全链条，确保在实际应用中大模型能够充分发挥作用。&lt;/p>
&lt;h2 id="书生-浦语全链条开源开放体系">书生-浦语全链条开源开放体系&lt;/h2>
&lt;p>书生·浦语大模型打破了传统的人工智能应用模式，提出了全链条开源开放体系。这一体系涵盖了从数据到预训练、微调、部署、评测到应用的全过程，为通用人工智能的实现提供了完整的解决方案。数据（&lt;a class="link" href="https://github.com/opendatalab/WanJuan1.0" target="_blank" rel="noopener"
>书生·万卷&lt;/a>）作为起点，经过&lt;a class="link" href="https://github.com/InternLM/InternLM" target="_blank" rel="noopener"
>IntermLM-Train&lt;/a>的预训练，使用&lt;a class="link" href="https://github.com/InternLM/xtuner" target="_blank" rel="noopener"
>XTuner&lt;/a>进行微调，通过&lt;a class="link" href="https://github.com/InternLM/lmdeploy" target="_blank" rel="noopener"
>LMDeploy&lt;/a>实现部署，通过&lt;a class="link" href="https://github.com/open-compass/opencompass" target="_blank" rel="noopener"
>OpenCompass&lt;/a>进行全面评测，最终应用在&lt;a class="link" href="https://github.com/InternLM/Lagent" target="_blank" rel="noopener"
>Lagent&lt;/a>构建的多模态智能体中。&lt;/p>
&lt;p>这一全链条开源开放体系，为大模型的发展提供了创新性的方法，促使人工智能更好地服务于多样化的现实需求。&lt;/p>
&lt;h3 id="数据覆盖多模态和任务">数据：覆盖多模态和任务&lt;/h3>
&lt;p>全链条开源体系以&lt;a class="link" href="https://github.com/opendatalab/WanJuan1.0" target="_blank" rel="noopener"
>书生-万卷&lt;/a>为基础，涵盖了多模态和多任务的数据需求，为模型的学习提供了全面支持。&lt;/p>
&lt;h4 id="opendatalab开放数据平台">OpenDataLab：开放数据平台&lt;/h4>
&lt;p>&lt;a class="link" href="https://github.com/opendatalab" target="_blank" rel="noopener"
>OpenDataLab&lt;/a>作为开放数据平台，不仅包含丰富多样的开放数据，还为大模型的发展提供了数据支持和实验平台。&lt;/p>
&lt;h3 id="预训练并行训练极致优化">预训练：并行训练，极致优化&lt;/h3>
&lt;p>&lt;a class="link" href="https://github.com/InternLM/InternLM" target="_blank" rel="noopener"
>InterLM&lt;/a>采用并行训练的方式，通过极致优化实现了高效的预训练，为模型的通用性奠定基础。&lt;/p>
&lt;h3 id="微调xtuner支持全参数微调支持lora等低成本微调">微调：XTuner，支持全参数微调，支持Lora等低成本微调&lt;/h3>
&lt;p>微调阶段使用&lt;a class="link" href="https://github.com/InternLM/xtuner" target="_blank" rel="noopener"
>XTuner&lt;/a>工具，支持全参数微调，同时还支持诸如Lora等低成本微调方法，使模型更好地适应各种特定任务。&lt;/p>
&lt;p>特性：&lt;/p>
&lt;ul>
&lt;li>增量续训：让基座模型学习新知识，垂直领域&lt;/li>
&lt;li>有监督微调：让模型学会理解和遵循各种指令。一般采用全量参数微调和部分参数微调等方法。&lt;/li>
&lt;li>多种微调算法：多种微调策略与算法，覆盖各类SFT场景。&lt;/li>
&lt;li>适配多种开源生态：支持加载HuggingFace、ModelScope模型或者数据级&lt;/li>
&lt;li>自动优化加速：开发者无需关注复杂的显存优化和计算加速细节&lt;/li>
&lt;/ul>
&lt;h3 id="部署lmdeploy全链路部署性能领先">部署：LMDeploy，全链路部署，性能领先&lt;/h3>
&lt;p>&lt;a class="link" href="https://github.com/InternLM/lmdeploy" target="_blank" rel="noopener"
>LMDeploy&lt;/a>提供了全链路部署的解决方案，包括模型轻量化、推理和服务，使得大模型在GPU上的部署更加高效，性能领先。&lt;/p>
&lt;h3 id="评测opencompass全方位评测性能可以复现全球领先的大模型开源评测体系">评测：OpenCompass，全方位评测，性能可以复现，全球领先的大模型开源评测体系&lt;/h3>
&lt;p>评测阶段使用&lt;a class="link" href="https://github.com/open-compass/opencompass" target="_blank" rel="noopener"
>OpenCompass&lt;/a>工具，全方位评测模型性能，保证了评测结果的复现性，成为全球领先的大模型开源评测体系。&lt;/p>
&lt;p>特性：&lt;/p>
&lt;ul>
&lt;li>丰富模型支持：开源模型、API模型一站式评测。&lt;/li>
&lt;li>分布式高效评测：支持千亿参数模型在海量数据集上分布式评测。&lt;/li>
&lt;li>便捷的数据集接口：支持社区用户根据自身需求快速添加自定义数据集。&lt;/li>
&lt;li>敏捷的能力迭代：每周更新大模型能力榜单。&lt;/li>
&lt;/ul>
&lt;h3 id="应用legentagentlego-支持多种智能体支持代码解释器和多种工具">应用：Legent、AgentLego 支持多种智能体，支持代码解释器和多种工具&lt;/h3>
&lt;p>最终，模型的应用在&lt;a class="link" href="https://github.com/InternLM/Lagent" target="_blank" rel="noopener"
>Legent&lt;/a>和&lt;a class="link" href="https://github.com/InternLM/Lagent" target="_blank" rel="noopener"
>AgentLego&lt;/a>等多种智能体中得以体现，支持代码解释器和多种工具，实现了多模态智能体的灵活应用。&lt;/p>
&lt;p>特性：&lt;/p>
&lt;ul>
&lt;li>丰富的工具集合，尤其是提供了大量视觉、多模态相关领域的工具。&lt;/li>
&lt;li>支持多个主流智能体系统，如LangChain、Transformers Agent、Lagent等。&lt;/li>
&lt;li>灵活的多模态工具调用接口，可以轻松支持各类输入输出格式的工具函数&lt;/li>
&lt;li>一键式远程工具部署，轻松使用和调试大模型智能体。&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>相关链接：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>书生·浦语大模型实战营地址：&lt;a class="link" href="https://github.com/InternLM/tutorial" target="_blank" rel="noopener"
>https://github.com/InternLM/tutorial&lt;/a>&lt;/li>
&lt;li>书生·万卷开源地址：&lt;a class="link" href="https://github.com/opendatalab/WanJuan1.0" target="_blank" rel="noopener"
>https://github.com/opendatalab/WanJuan1.0&lt;/a>&lt;/li>
&lt;li>InternLM开源地址：&lt;a class="link" href="https://github.com/InternLM/InternLM" target="_blank" rel="noopener"
>https://github.com/InternLM/InternLM&lt;/a>&lt;/li>
&lt;li>XTuner开源地址：&lt;a class="link" href="https://github.com/InternLM/xtuner" target="_blank" rel="noopener"
>https://github.com/InternLM/xtuner&lt;/a>&lt;/li>
&lt;li>LMDeploy开源地址：&lt;a class="link" href="https://github.com/InternLM/lmdeploy" target="_blank" rel="noopener"
>https://github.com/InternLM/lmdeploy&lt;/a>&lt;/li>
&lt;li>OpenCompass开源地址：&lt;a class="link" href="https://github.com/open-compass/opencompass" target="_blank" rel="noopener"
>https://github.com/open-compass/opencompass&lt;/a>&lt;/li>
&lt;li>OpenDataLab地址：&lt;a class="link" href="https://opendatalab.org.cn/" target="_blank" rel="noopener"
>https://opendatalab.org.cn/&lt;/a>&lt;/li>
&lt;li>OpenDataLab开源地址：&lt;a class="link" href="https://github.com/opendatalab" target="_blank" rel="noopener"
>https://github.com/opendatalab&lt;/a>&lt;/li>
&lt;/ul></description></item></channel></rss>
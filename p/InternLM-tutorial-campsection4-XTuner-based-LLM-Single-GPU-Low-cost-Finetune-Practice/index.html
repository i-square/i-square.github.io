<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="本文为书生·浦语大模型实战营的课程笔记系列第四节：XTuner 大模型单卡低成本微调实战"><meta name=keywords content="internlm,LLM,tutorial,xtuner"><title>书生·浦语大模型实战营（四）：XTuner 大模型单卡低成本微调实战</title>
<link rel=canonical href=https://i-square.github.io/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/><link rel=stylesheet href=/scss/style.min.abbd69b2908fdfcd5179898beaafd374514a86538d81639ddd2c58c06ae54e40.css><meta property="og:title" content="书生·浦语大模型实战营（四）：XTuner 大模型单卡低成本微调实战"><meta property="og:description" content="本文为书生·浦语大模型实战营的课程笔记系列第四节：XTuner 大模型单卡低成本微调实战"><meta property="og:url" content="https://i-square.github.io/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/"><meta property="og:site_name" content="平方君的后花园"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="书生·浦语"><meta property="article:tag" content="大模型"><meta property="article:tag" content="开源"><meta property="article:tag" content="微调"><meta property="article:published_time" content="2024-01-12T09:50:54+08:00"><meta property="article:modified_time" content="2024-01-12T09:50:54+08:00"><meta property="og:image" content="https://i-square.github.io/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/head.webp"><meta name=twitter:title content="书生·浦语大模型实战营（四）：XTuner 大模型单卡低成本微调实战"><meta name=twitter:description content="本文为书生·浦语大模型实战营的课程笔记系列第四节：XTuner 大模型单卡低成本微调实战"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i-square.github.io/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/head.webp"><link rel="shortcut icon" href=/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-S4LP96619L"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-S4LP96619L",{anonymize_ip:!1})}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu5ad7b3c288b7ec9c6597012c8b723e22_6153_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>💤</span></figure><div class=site-meta><h1 class=site-name><a href=/>平方君的后花园</a></h1><h2 class=site-description>人生苦短，及时行乐。</h2></div></header><ol class=social-menu><li><a href=mailto:i_square@qq.com target=_blank title=E-Mail rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-mail" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 5m0 2a2 2 0 012-2h14a2 2 0 012 2v10a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><path d="M3 7l9 6 9-6"/></svg></a></li><li><a href=https://github.com/i-square target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>主页 | Home</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>归档 | Archives</span></a></li><li><a href=/categories/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg><span>分类 | Categories</span></a></li><li><a href=/tags/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-tag" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11 3l9 9a1.5 1.5.0 010 2l-6 6a1.5 1.5.0 01-2 0L3 11V7a4 4 0 014-4h4"/><circle cx="9" cy="9" r="2"/></svg><span>标签 | Tags</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>搜索 | Search</span></a></li><li><a href=/links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg><span>链接 | Links</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>关于 | About</span></a></li><li><a href=https://i-square.github.io/love target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-heart" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M19.5 12.572 12 20l-7.5-7.428A5 5 0 1112 6.006a5 5 0 117.5 6.572"/></svg><span>Love Story</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://i-square.github.io/ selected>中文</option><option value=https://i-square.github.io/en/>English</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>暗色模式</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#前言>前言</a></li><li><a href=#finetune简介>Finetune简介</a><ol><li><a href=#增量预训练微调>增量预训练微调</a></li><li><a href=#指令跟随微调>指令跟随微调</a></li><li><a href=#对话模板>对话模板</a></li><li><a href=#lora--qlora>LoRA & QLoRA</a><ol><li><a href=#lora-low-rank-adaptation-of-large-language-models>LoRA: Low-Rank Adaptation of Large Language Models</a></li><li><a href=#qlora-quantized-llms-with-low-rank-adapters>QLoRA: Quantized LLMs with Low-Rank Adapters</a></li><li><a href=#全量微调loraqlora对比>全量微调、LoRA、QLoRA对比</a></li></ol></li></ol></li><li><a href=#xtuner简介>XTuner简介</a></li><li><a href=#xtuner快速上手>XTuner快速上手</a><ol><li><a href=#自定义微调数据>自定义微调数据</a></li><li><a href=#ms-agent-数据集>MS-Agent 数据集</a></li><li><a href=#lagent调用实战>lagent调用实战</a><ol><li><a href=#测试验证>测试验证</a></li></ol></li></ol></li><li><a href=#作业>作业</a><ol><li><a href=#基础作业>基础作业</a></li><li><a href=#进阶作业>进阶作业</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/><img src=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/head_hu7d851f937bb6edd73b0f514358157b71_30618_800x0_resize_q75_h2_box_2.webp srcset="/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/head_hu7d851f937bb6edd73b0f514358157b71_30618_800x0_resize_q75_h2_box_2.webp 800w, /p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/head_hu7d851f937bb6edd73b0f514358157b71_30618_1600x0_resize_q75_h2_box_2.webp 1600w" width=800 height=341 loading=lazy alt="Featured image of post 书生·浦语大模型实战营（四）：XTuner 大模型单卡低成本微调实战"></a></div><div class=article-details><header class=article-category><a href=/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>学习笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/>书生·浦语大模型实战营（四）：XTuner 大模型单卡低成本微调实战</a></h2><h3 class=article-subtitle>本文为书生·浦语大模型实战营的课程笔记系列第四节：XTuner 大模型单卡低成本微调实战</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Jan 12, 2024</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>阅读时长: 3 分钟</time></div></footer></div></header><section class=article-content><h2 id=前言>前言</h2><p>本文为<a class=link href=https://github.com/InternLM/tutorial target=_blank rel=noopener>书生·浦语大模型实战营</a>的课程笔记系列第四节</p><ul><li>教学视频：<a class=link href=https://www.bilibili.com/video/BV1yK4y1B75J/ target=_blank rel=noopener>B站 BV1yK4y1B75J</a></li><li>配套文档：<a class=link href=https://github.com/InternLM/tutorial/blob/main/xtuner/README.md target=_blank rel=noopener>InternLM/tutorial xtuner</a></li></ul><h2 id=finetune简介>Finetune简介</h2><p>LLM 的下游应用中，<strong>增量预训练</strong>和<strong>指令跟随</strong>是经常会用到两种的微调模式</p><p><img src=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/finetune.webp width=1441 height=105 srcset="/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/finetune_huef66cf2caa2bdae3207a736027637305_15282_480x0_resize_q75_h2_box_2.webp 480w, /p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/finetune_huef66cf2caa2bdae3207a736027637305_15282_1024x0_resize_q75_h2_box_2.webp 1024w" loading=lazy alt=finetune class=gallery-image data-flex-grow=1372 data-flex-basis=3293px></p><h3 id=增量预训练微调>增量预训练微调</h3><ul><li>使用场景：让基座模型学习到一些新知识，如某个垂类领域的常识</li><li>训练数据：文章、书籍、代码等</li><li>数据构成：没有 <code>System</code> 和 <code>Input</code>，只有 <code>Output</code>，全部参与loss计算</li></ul><h3 id=指令跟随微调>指令跟随微调</h3><ul><li>使用场景：让模型学会对话模板，根据人类指令进行对话</li><li>训练数据：高质量的对话、问答数据</li><li>数据构成：包含 <code>System</code>、<code>Input</code> 和 <code>Output</code> ，但只有 <code>Output</code> 部分参与loss计算</li></ul><h3 id=对话模板>对话模板</h3><ul><li>对话模板是为了能够让 LLM 区分出 <strong>System</strong>、<strong>User</strong> 和 <strong>Assistant</strong></li><li>不同的模型会有不同的模板</li></ul><p><img src=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/chat_template.webp width=1693 height=718 srcset="/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/chat_template_hu3ec7abb32f2ce92791a8f7db528daec1_73986_480x0_resize_q75_h2_box_2.webp 480w, /p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/chat_template_hu3ec7abb32f2ce92791a8f7db528daec1_73986_1024x0_resize_q75_h2_box_2.webp 1024w" loading=lazy alt=chat_template class=gallery-image data-flex-grow=235 data-flex-basis=565px></p><h3 id=lora--qlora>LoRA & QLoRA</h3><h4 id=lora-low-rank-adaptation-of-large-language-models>LoRA: Low-Rank Adaptation of Large Language Models</h4><ul><li>LLM 的参数量主要集中在模型中的 Linear, 训练这些参数会耗费大量的显存</li><li>LoRA 通过在原本的 Linear 旁，新增一个支路，包含两个连续的小 linear，新增的这个支路通常叫做 Adapter</li><li>Adapter 参数量远小于原本的 Linear，能大幅降低训练的显存消耗</li></ul><h4 id=qlora-quantized-llms-with-low-rank-adapters>QLoRA: Quantized LLMs with Low-Rank Adapters</h4><ul><li>4位NormalFloat量化：这是一种改进量化的方法，确保每个量化仓中有相同数量的值，这避免了计算问题和异常值的错误。</li><li>双量化：对量化常量再次量化以节省额外内存的过程。</li><li>统一内存分页：它依赖于NVIDIA统一内存管理，自动处理CPU和GPU之间的页到页传输，它可以保证GPU处理无错，特别是在GPU可能耗尽内存的情况下。</li></ul><h4 id=全量微调loraqlora对比>全量微调、LoRA、QLoRA对比</h4><p><img src=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/finetune_compare.webp width=1463 height=800 srcset="/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/finetune_compare_hu683ce0fd2081c91d802ac80b2ad43a34_60268_480x0_resize_q75_h2_box_2.webp 480w, /p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/finetune_compare_hu683ce0fd2081c91d802ac80b2ad43a34_60268_1024x0_resize_q75_h2_box_2.webp 1024w" loading=lazy alt=finetune_compare class=gallery-image data-flex-grow=182 data-flex-basis=438px></p><h2 id=xtuner简介>XTuner简介</h2><p>详见 <a class=link href=https://github.com/InternLM/xtuner target=_blank rel=noopener>XTuner</a> 的官方仓库</p><h2 id=xtuner快速上手>XTuner快速上手</h2><p>参考配套教学文档：<a class=link href=https://github.com/InternLM/tutorial/blob/main/xtuner/README.md target=_blank rel=noopener>InternLM/tutorial xtuner</a></p><h3 id=自定义微调数据>自定义微调数据</h3><p>按照教学文档，实操一遍即可，XTuner 上手确实很简单</p><h3 id=ms-agent-数据集>MS-Agent 数据集</h3><p>这个数据集比较有意思，能够赋予大模型调用api的agent能力，原理：</p><ul><li>模型的回复中会包括插件调用代码和执行代码<ul><li>调用代码是 LLM 生成的</li><li>执行代码是需要调用服务来生成结果的，这里我们需要给 <code>xtuner chat</code> 增加 <code>--lagent</code> 参数来实现</li></ul></li></ul><h3 id=lagent调用实战>lagent调用实战</h3><p>本次继续沿用之前课程配置的 <a class=link href=https://studio.intern-ai.org.cn/ target=_blank rel=noopener>InternStudio</a> 平台开发机</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># conda环境创建</span>
</span></span><span class=line><span class=cl>conda create --name xtuner0.1.9 <span class=nv>python</span><span class=o>=</span>3.10 -y
</span></span><span class=line><span class=cl>conda activate xtuner0.1.9
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>cd</span> ~ <span class=o>&amp;&amp;</span> mkdir xtuner019 <span class=o>&amp;&amp;</span> <span class=nb>cd</span> xtuner019
</span></span><span class=line><span class=cl>git clone -b v0.1.9 https://gitee.com/Internlm/xtuner
</span></span><span class=line><span class=cl><span class=nb>cd</span> xtuner
</span></span><span class=line><span class=cl>pip install -e <span class=s1>&#39;.[all]&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 资源准备</span>
</span></span><span class=line><span class=cl>mkdir ~/ft-msagent <span class=o>&amp;&amp;</span> <span class=nb>cd</span> ~/ft-msagent
</span></span><span class=line><span class=cl>cp -r /root/share/temp/model_repos/internlm-chat-7b/ .
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 用modelscope下载微调参数</span>
</span></span><span class=line><span class=cl>pip install modelscope
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 保存 download.py</span>
</span></span><span class=line><span class=cl>cat <span class=s>&lt;&lt; EOF &gt; download.py
</span></span></span><span class=line><span class=cl><span class=s>from modelscope import snapshot_download
</span></span></span><span class=line><span class=cl><span class=s>model_dir = snapshot_download(&#39;xtuner/internlm-7b-qlora-msagent-react&#39;)
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 指定保存路径到当前目录</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>MODELSCOPE_CACHE</span><span class=o>=</span><span class=sb>`</span><span class=nb>pwd</span><span class=sb>`</span>
</span></span><span class=line><span class=cl>python download.py <span class=c1># 模型下载到了 xtuner/internlm-7b-qlora-msagent-react</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置 serper 环境变量</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>SERPER_API_KEY</span><span class=o>=</span>xxx
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 启动</span>
</span></span><span class=line><span class=cl>xtuner chat ./internlm-chat-7b --adapter xtuner/internlm-7b-qlora-msagent-react --lagent
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 报错的话，按照教学文档处理</span>
</span></span><span class=line><span class=cl>vim /root/xtuner019/xtuner/xtuner/tools/chat.py <span class=c1># 按文档修改，注释掉139行 &#39;trust_remote_code&#39;: True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 重新启动</span>
</span></span><span class=line><span class=cl>xtuner chat ./internlm-chat-7b --adapter xtuner/internlm-7b-qlora-msagent-react --lagent
</span></span></code></pre></td></tr></table></div></div><h4 id=测试验证>测试验证</h4><p><em>prompt: 你好，西安明天天气怎么样？</em></p><ul><li>结果图：<ul><li>教学视频里回答失败了，但我自己部署是成功的</li></ul></li></ul><p><img src=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/chat_lagent.png width=1248 height=204 srcset="/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/chat_lagent_hu5bafbf7b8738257202ae5dda08b0a37c_16529_480x0_resize_box_3.png 480w, /p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/screenshots/chat_lagent_hu5bafbf7b8738257202ae5dda08b0a37c_16529_1024x0_resize_box_3.png 1024w" loading=lazy alt=chat_lagent class=gallery-image data-flex-grow=611 data-flex-basis=1468px></p><h2 id=作业>作业</h2><h3 id=基础作业>基础作业</h3><blockquote><p>目标：构建数据集，使用 XTuner 微调 InternLM-Chat-7B 模型, 让模型学习到它是你的智能小助手，效果如下图所示，本作业训练出来的模型的输出需要<strong>将不要葱姜蒜大佬</strong>替换成自己名字或昵称！</p></blockquote><p>作业参考文档： <a class=link href=https://github.com/InternLM/tutorial/blob/main/xtuner/self.md target=_blank rel=noopener>XTuner InternLM-Chat 个人小助手认知微调实践</a></p><ul><li>训练最后的 eval chat结果已经有变化了：</li></ul><p><img src=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/homework/eval_chat.png width=945 height=430 srcset="/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/homework/eval_chat_hu5e1a3206595256d802f2e2e466aed5e3_32738_480x0_resize_box_3.png 480w, /p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/homework/eval_chat_hu5e1a3206595256d802f2e2e466aed5e3_32738_1024x0_resize_box_3.png 1024w" loading=lazy alt=eval_chat class=gallery-image data-flex-grow=219 data-flex-basis=527px></p><ul><li>Web Demo 结果图：<ul><li>其中前3条是我给的训练数据，后面两条是模型自己学习到的</li></ul></li></ul><p><img src=/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/homework/self.png width=751 height=852 srcset="/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/homework/self_hu86f2eef6c30de5d908adb3ca0ab1f673_21396_480x0_resize_box_3.png 480w, /p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/homework/self_hu86f2eef6c30de5d908adb3ca0ab1f673_21396_1024x0_resize_box_3.png 1024w" loading=lazy alt=self class=gallery-image data-flex-grow=88 data-flex-basis=211px></p><h3 id=进阶作业>进阶作业</h3><blockquote><p>目标：</p><ul><li>将训练好的Adapter模型权重上传到 OpenXLab、Hugging Face 或者 MoelScope 任一一平台。</li><li>将训练好后的模型应用部署到 OpenXLab 平台，参考部署文档请访问：https://aicarrier.feishu.cn/docx/MQH6dygcKolG37x0ekcc4oZhnCe</li></ul></blockquote><p>由于时间关系，进阶作业没有计划做</p></section><footer class=article-footer><section class=article-tags><a href=/tags/%E4%B9%A6%E7%94%9F%E6%B5%A6%E8%AF%AD/>书生·浦语</a>
<a href=/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/>大模型</a>
<a href=/tags/%E5%BC%80%E6%BA%90/>开源</a>
<a href=/tags/%E5%BE%AE%E8%B0%83/>微调</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/InternLM-tutorial-campsection5-LLM-Quantization-Deployment-Practice-based-on-LMDeploy/><div class=article-image><img src=/p/InternLM-tutorial-campsection5-LLM-Quantization-Deployment-Practice-based-on-LMDeploy/cover.a3be63869db3bc1c3a2e32d9248c7ebf_hu5ff21984f10fb646805c01ab57928b76_27538_250x150_fill_q75_h2_box_smart1_2.webp width=250 height=150 loading=lazy alt="Featured image of post 书生·浦语大模型实战营（五）：LMDeploy 大模型量化部署实践" data-key="InternLM tutorial camp(section5): LLM Quantization Deployment Practice based on LMDeploy" data-hash="md5-o75jhp2zvBw6LjLZJIx+vw=="></div><div class=article-details><h2 class=article-title>书生·浦语大模型实战营（五）：LMDeploy 大模型量化部署实践</h2></div></a></article><article class=has-image><a href=/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/><div class=article-image><img src=/p/InternLM-tutorial-campsection3-Build-Knowledge-Base-Using-InternLM-and-LangChain/head.2a611c6d955d13fb31c9ebb9a3190f6b_hu73fdf6953030a375e3def8cd81131f22_28186_250x150_fill_q75_h2_box_smart1_2.webp width=250 height=150 loading=lazy alt="Featured image of post 书生·浦语大模型实战营（三）：基于 InternLM 和 LangChain 搭建你的知识库" data-key="InternLM tutorial camp(section3): Build Knowledge Base Using InternLM and LangChain" data-hash="md5-KmEcbZVdE/sxyeu5oxkPaw=="></div><div class=article-details><h2 class=article-title>书生·浦语大模型实战营（三）：基于 InternLM 和 LangChain 搭建你的知识库</h2></div></a></article><article class=has-image><a href=/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/><div class=article-image><img src=/p/InternLM-tutorial-campsection2-Easy-Fun-with-InternLM-Entertaining-Demo/head.5420ac06d24367df6f58385aa9496f2d_hue03d992ed6f6045ef4df175483822a62_29868_250x150_fill_q75_h2_box_smart1_2.webp width=250 height=150 loading=lazy alt="Featured image of post 书生·浦语大模型实战营（二）：轻松玩转书生·浦语大模型趣味Demo" data-key="InternLM tutorial camp(section2): Easy Fun with InternLM - Entertaining Demo" data-hash="md5-VCCsBtJDZ99vWDhaqUlvLQ=="></div><div class=article-details><h2 class=article-title>书生·浦语大模型实战营（二）：轻松玩转书生·浦语大模型趣味Demo</h2></div></a></article><article class=has-image><a href=/p/InternLM-tutorial-campsection1-LLM-Full-Stack-Open-Source-Ecosystem/><div class=article-image><img src=/p/InternLM-tutorial-campsection1-LLM-Full-Stack-Open-Source-Ecosystem/camp.49fa5e7d1bb8cff80fd5d3e5422e107c_hu675ae48102060cb1e10f720f447d4bf2_26310_250x150_fill_q75_h2_box_smart1_2.webp width=250 height=150 loading=lazy alt="Featured image of post 书生·浦语大模型实战营（一）：书生·浦语大模型全链路开源体系" data-key="InternLM tutorial camp(section1): LLM Full-Stack Open Source Ecosystem" data-hash="md5-SfpefRu4z/gP1dPlQi4QfA=="></div><div class=article-details><h2 class=article-title>书生·浦语大模型实战营（一）：书生·浦语大模型全链路开源体系</h2></div></a></article><article><a href=/p/Data-structure-study-notes-8-Disjoint-set-classes/><div class=article-details><h2 class=article-title>数据结构学习笔记（八）：不相交集类</h2></div></a></article></div></div></aside><div id=cusdis_thread data-host=https://cusdis.com data-app-id=0d2babe1-c058-48ca-a64b-c5afdfa1cb19 data-page-id=9e9aa2226dbd7415c59f4ef9a678f023 data-page-url=https://i-square.github.io/p/InternLM-tutorial-campsection4-XTuner-based-LLM-Single-GPU-Low-cost-Finetune-Practice/ data-page-title="书生·浦语大模型实战营（四）：XTuner 大模型单卡低成本微调实战"></div><script async defer src=https://cusdis.com/js/cusdis.es.js></script><script>function setCusdisTheme(e){let t=document.querySelector("#cusdis_thread iframe");t&&window.CUSDIS.setTheme(e)}window.addEventListener("onColorSchemeChange",e=>{setCusdisTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2017 -
2024 平方君的后花园</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.21.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>